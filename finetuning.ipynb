{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rachel/directory-envs/3d'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Clear GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Reset memory allocations and cache\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.reset_accumulated_memory_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rachel/directory-envs/3d/InstantMesh\n"
     ]
    }
   ],
   "source": [
    "cd InstantMesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= length of dataset 384 =============\n",
      "============= length of dataset 16 =============\n",
      "Conditional Image Shape: torch.Size([6, 4, 1024, 1024])\n",
      "Target Images Shape: torch.Size([6, 6, 4, 320, 320])\n"
     ]
    }
   ],
   "source": [
    "from src.data.objaverse_zero123plus import ObjaverseData\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load training data\n",
    "train_dataset = ObjaverseData(root_dir='20240924_3D Dataset', validation=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=6, num_workers=8, shuffle=True)\n",
    "\n",
    "# Load validation data\n",
    "val_dataset = ObjaverseData(root_dir='20240924_3D Dataset', validation=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=6, num_workers=8, shuffle=False)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(\"Conditional Image Shape:\", batch['cond_imgs'].shape)  # (6, 3, H, W)\n",
    "    print(\"Target Images Shape:\", batch['target_imgs'].shape)    # (6, 6, 3, H, W)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Running on GPUs 0,1\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.73it/s]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "============= length of dataset 384 =============\n",
      "============= length of dataset 16 =============\n",
      "accumulate_grad_batches = 1\n",
      "++++ NOT USING LR SCALING ++++\n",
      "Setting learning rate to 1.00e-05\n",
      "[rank: 0] Seed set to 42\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n",
      "[rank: 1] Seed set to 42\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.93it/s]\n",
      "============= length of dataset 384 =============\n",
      "============= length of dataset 16 =============\n",
      "[rank: 1] Seed set to 42\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 2 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "============= length of dataset 384 =============\n",
      "============= length of dataset 384 =============\n",
      "============= length of dataset 16 =============\n",
      "============= length of dataset 16 =============\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Project config\n",
      "model:\n",
      "  base_learning_rate: 1.0e-05\n",
      "  target: zero123plus.model.MVDiffusion\n",
      "  params:\n",
      "    drop_cond_prob: 0.1\n",
      "    stable_diffusion_config:\n",
      "      pretrained_model_name_or_path: sudo-ai/zero123plus-v1.2\n",
      "      custom_pipeline: ./zero123plus\n",
      "data:\n",
      "  target: src.data.objaverse_zero123plus.DataModuleFromConfig\n",
      "  params:\n",
      "    batch_size: 2\n",
      "    num_workers: 8\n",
      "    train:\n",
      "      target: src.data.objaverse_zero123plus.ObjaverseData\n",
      "      params:\n",
      "        root_dir: 20240924_3D Dataset\n",
      "        validation: false\n",
      "    validation:\n",
      "      target: src.data.objaverse_zero123plus.ObjaverseData\n",
      "      params:\n",
      "        root_dir: 20240924_3D Dataset\n",
      "        validation: true\n",
      "lightning:\n",
      "  modelcheckpoint:\n",
      "    params:\n",
      "      every_n_train_steps: 1000\n",
      "      save_top_k: -1\n",
      "      save_last: true\n",
      "  callbacks: {}\n",
      "  trainer:\n",
      "    benchmark: true\n",
      "    max_epochs: -1\n",
      "    gradient_clip_val: 1.0\n",
      "    val_check_interval: 1000\n",
      "    num_sanity_val_steps: 0\n",
      "    accumulate_grad_batches: 1\n",
      "    check_val_every_n_epoch: null\n",
      "    accelerator: gpu\n",
      "    devices: 2\n",
      "\n",
      "[rank1]: Traceback (most recent call last):\n",
      "[rank1]:   File \"/home/rachel/directory-envs/3d/InstantMesh/train.py\", line 286, in <module>\n",
      "[rank1]:     trainer.fit(model, data)\n",
      "[rank1]:   File \"/home/rachel/directory-envs/3d/meshing/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 544, in fit\n",
      "[rank1]:     call._call_and_handle_interrupt(\n",
      "[rank1]:   File \"/home/rachel/directory-envs/3d/meshing/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "[rank1]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "[rank1]:   File \"/home/rachel/directory-envs/3d/meshing/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py\", line 102, in launch\n",
      "[rank1]:     return function(*args, **kwargs)\n",
      "[rank1]:   File \"/home/rachel/directory-envs/3d/meshing/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n",
      "[rank1]:     self._run(model, ckpt_path=ckpt_path)\n",
      "[rank1]:   File \"/home/rachel/directory-envs/3d/meshing/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 970, in _run\n",
      "[rank1]:     call._call_lightning_module_hook(self, \"on_fit_start\")\n",
      "[rank1]:   File \"/home/rachel/directory-envs/3d/meshing/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "[rank1]:     output = fn(*args, **kwargs)\n",
      "[rank1]:   File \"/home/rachel/directory-envs/3d/InstantMesh/zero123plus/model.py\", line 98, in on_fit_start\n",
      "[rank1]:     self.pipeline.to(device)\n",
      "[rank1]:   File \"/home/rachel/directory-envs/3d/meshing/lib/python3.10/site-packages/diffusers/pipelines/pipeline_utils.py\", line 431, in to\n",
      "[rank1]:     module.to(device, dtype)\n",
      "[rank1]:   File \"/home/rachel/directory-envs/3d/meshing/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 2958, in to\n",
      "[rank1]:     return super().to(*args, **kwargs)\n",
      "[rank1]:   File \"/home/rachel/directory-envs/3d/meshing/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1174, in to\n",
      "[rank1]:     return self._apply(convert)\n",
      "[rank1]:   File \"/home/rachel/directory-envs/3d/meshing/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "[rank1]:     module._apply(fn)\n",
      "[rank1]:   File \"/home/rachel/directory-envs/3d/meshing/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "[rank1]:     module._apply(fn)\n",
      "[rank1]:   File \"/home/rachel/directory-envs/3d/meshing/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "[rank1]:     module._apply(fn)\n",
      "[rank1]:   [Previous line repeated 3 more times]\n",
      "[rank1]:   File \"/home/rachel/directory-envs/3d/meshing/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 805, in _apply\n",
      "[rank1]:     param_applied = fn(param)\n",
      "[rank1]:   File \"/home/rachel/directory-envs/3d/meshing/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in convert\n",
      "[rank1]:     return t.to(\n",
      "[rank1]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 1 has a total capacity of 8.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 7.16 GiB is allocated by PyTorch, and 129.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[rank: 1] Child process with PID 59218 terminated with code 1. Forcefully terminating all other processes to avoid zombies ðŸ§Ÿ\n"
     ]
    }
   ],
   "source": [
    "!python train.py --base configs/zero123plus-finetune.yaml --gpus 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meshing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
